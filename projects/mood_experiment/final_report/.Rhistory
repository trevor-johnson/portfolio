filtered_d[response_id %in% bad_ids]
full_data
full_data[, select(.SD, resopnse_id, i_am_the_life_of_the_party:i_am_full_of_ideas)]
full_data[, select(.SD, response_id, i_am_the_life_of_the_party:i_am_full_of_ideas)]
d <- fread('../data/W241_Survey_Results_Clean.csv')
full_data <- fread('../data/full_data.csv')
# more data cleaning
filtered_d <- d %>%
# filter out bad data. Can decide later what isn't necessary to filter out.
filter(
#complier == TRUE,  # 39 non-compliers
duration_in_seconds <= 1000,  # 23 ppl took more than 1000 seconds and are outliers
!(taken_test_before == 'Yes' & familiar_with_test == 'No'),  # 6 ppl not answering questions correctly
(what_is_your_gender == gender), # 9 ppl answered their gender incorrectly
how_old_are_you == how_old_are_you2,  # 22 ppl answered their age incorrectly
response_id != bad_ids, # 17 people answered 45/50 of the questiosn with the same answer
) %>%
# drop unnecessary vars
# we didn't get recipient name info, everyone finished, and other vars are unnecessary
select(-how_old_are_you2, -recipient_last_name:-external_data_reference,
-response_type, -progress, -finished, -distribution_channel, -user_language, -rid)
library(data.table)
library(tidyverse)
library(janitor)
library(ggplot2)
library(dplyr)
library(patchwork)
library(tidyverse)
library(lmtest)
library(stargazer)
library(sandwich)
library(knitr)
d <- fread('../data/W241_Survey_Results_Clean.csv')
full_data <- fread('../data/full_data.csv')
# checking out fishy responses from the full dataset
q_cols <- full_data %>% select(i_am_the_life_of_the_party:i_am_full_of_ideas) %>% names()
df_long <- melt.data.table(full_data, measure.vars = q_cols, variable.name = "question", value.name = "answer")
# 10 people just put the same thing every time
# df_long[,.N, by = c("response_id", "answer")][N == 50]
# 17 people basically put the same answer all the way down, with only slight variations
# df_long[,.N, by = c("response_id", "answer")][N >= 45]
# save the IDs of these 17 people to filter out later
bad_ids <- df_long[,.N, by = c("response_id", "answer")][N >= 45]$response_id
# define complier and treatment variables
d[, ":=" (
complier = ifelse(((d[, dob_day] %% 2 == 1) & (d[, compliance_q_glass] == 'Confetti (colored)')) |
((d[, dob_day] %% 2 == 0) & (d[, compliance_q_mclaughlin] == 'Fish')), TRUE, FALSE),
treatment = ifelse(d[, dob_day] %% 2 == 0, 1, 0)
)]
# Binarize hispanic variable
d[, hispanic := ifelse(hispanic %in% c(1, 15), 0, 1)]
# make some vars more descriptive
d[, ':=' (
# Simplify ethnicity breakdowns
ethnicity = fcase(
ethnicity == 1, "White",
ethnicity == 2, "Black or African American",
ethnicity %in% c(4, 5, 6, 7, 8, 9, 10), "Asian",
default = "Other"),
region = fcase(
region == 1, "Northeast",
region == 2, "Midwest",
region == 3, "South",
region == 4, "West",
default = "idk"),
education = fcase(
education == 1, "Some high school or less",
education == 2, "High school graduate",
education == 3, "Other post high school vocational training",
education == 4, "Completed some college, but no degree",
education == 5, "Associate's degree",
education == 6, "Bachelor's degree",
education == 7, "Master's or professional degree",
education == 8, "Doctorate degree",
default = "idk"),
gender = ifelse(gender == 1, "Male", "Female")
)]
# Create this variable just to compare with the other variable `how_old_are_you` and filter out discrepancies
d[, how_old_are_you2 := fcase(
age >= 18 & age <= 24, "18-24 years old",
age >= 25 & age <= 34, "25-34 years old",
age >= 35 & age <= 44, "35-44 years old",
age >= 45 & age <= 54, "45-54 years old",
age >= 55 & age <= 64, "55-64 years old",
age >= 65, "65+ years old",
default = "idk"
)]
# more data cleaning
filtered_d <- d %>%
# filter out bad data. Can decide later what isn't necessary to filter out.
filter(
#complier == TRUE,  # 39 non-compliers
duration_in_seconds <= 1000,  # 23 ppl took more than 1000 seconds and are outliers
!(taken_test_before == 'Yes' & familiar_with_test == 'No'),  # 6 ppl not answering questions correctly
(what_is_your_gender == gender), # 9 ppl answered their gender incorrectly
how_old_are_you == how_old_are_you2,  # 22 ppl answered their age incorrectly
response_id != bad_ids, # 17 people answered 45/50 of the questiosn with the same answer
) %>%
# drop unnecessary vars
# we didn't get recipient name info, everyone finished, and other vars are unnecessary
select(-how_old_are_you2, -recipient_last_name:-external_data_reference,
-response_type, -progress, -finished, -distribution_channel, -user_language, -rid)
dim(d)
dim(filtered_d)
# function to run one power test
# i run a regression on each factor individually
# recommended to set the alpha to .05/5 for bonferonni adjustment
power_analysis_one_test <- function(samp_size = 50, treatment_split = .5,
force_even_split = T, tau = -5, factor_mean = 50,
factor_sd = 10, alpha = .01){
# sample ppl and put them into treatment or control. Depends on if we want even splits or not
if (force_even_split){
df <- data.table(condition = c(rep("treatment", round(samp_size/2,0)), rep("control", round(samp_size/2,0))))
}else{
df <- data.table(condition = sample(c("treatment", "control"), size = samp_size, replace = T))
}
# now sample from the normal distribution to assign the treatment effect.
# if they are in treatment, they get the added "tau" effect.
# control just gets rnorm()
for (i in 1:5){
df[, paste0("factor", i) := ifelse(condition == "treatment",
rnorm(nrow(df[condition == "treatment",]), factor_mean + tau, factor_sd),
rnorm(nrow(df[condition == "control",]), factor_mean, factor_sd)
)]
}
# finally, calculate p-value for every personality factor
pvals <- c()
for (i in 1:5){
fit <- summary(lm(as.formula(paste0("factor", i, "~ condition")), data = df))
pval <- fit$coefficients[2,4]
pvals <- c(pvals, pval)
}
# are any of them significant?
sig <- sum(pvals < alpha) > 0
# return boolean for if it's significant or not
return(sig)
}
# Changing the sample size and running the experiment 1,000 times at various sample sizes and calculating the power.
adjust_sample_size <- function(samp_sizes, iter=1000, verbose=F){
output_samp_size <- c()
for (i in samp_sizes){
output_samp_size <- c(output_samp_size,
mean(sapply(1:iter, function(x) power_analysis_one_test(
samp_size = i, treatment_split = .5, force_even_split = T,
tau = 3, factor_mean = 50, factor_sd = 15))))
if(verbose){
print(paste0("Sample size ", i, " done."))
}
}
df_out <- data.table(
sample_size = samp_sizes,
power = output_samp_size
)
return(df_out)
}
set.seed(1)
df1 <- adjust_sample_size(seq(50, 500, 50), iter=300)
# plot
df1 %>%
ggplot(aes(x = sample_size, y = power)) +
geom_line() +
labs(title = "Power as Sample Size Increases",
subtitle = "Assumes test scores have a standard deviation of 15, with a treatment effect of 3",
y = "Power", x = "Sample Size") +
theme_minimal()
library(data.table)
library(tidyverse)
library(janitor)
library(ggplot2)
library(dplyr)
library(patchwork)
library(tidyverse)
library(lmtest)
library(stargazer)
library(sandwich)
library(knitr)
d <- fread('../data/W241_Survey_Results_Clean.csv')
full_data <- fread('../data/full_data.csv')
# checking out fishy responses from the full dataset
q_cols <- full_data %>% select(i_am_the_life_of_the_party:i_am_full_of_ideas) %>% names()
df_long <- melt.data.table(full_data, measure.vars = q_cols, variable.name = "question", value.name = "answer")
# 10 people just put the same thing every time
# df_long[,.N, by = c("response_id", "answer")][N == 50]
# 17 people basically put the same answer all the way down, with only slight variations
# df_long[,.N, by = c("response_id", "answer")][N >= 45]
# save the IDs of these 17 people to filter out later
bad_ids <- df_long[,.N, by = c("response_id", "answer")][N >= 45]$response_id
# define complier and treatment variables
d[, ":=" (
complier = ifelse(((d[, dob_day] %% 2 == 1) & (d[, compliance_q_glass] == 'Confetti (colored)')) |
((d[, dob_day] %% 2 == 0) & (d[, compliance_q_mclaughlin] == 'Fish')), TRUE, FALSE),
treatment = ifelse(d[, dob_day] %% 2 == 0, 1, 0)
)]
# Binarize hispanic variable
d[, hispanic := ifelse(hispanic %in% c(1, 15), 0, 1)]
# make some vars more descriptive
d[, ':=' (
# Simplify ethnicity breakdowns
ethnicity = fcase(
ethnicity == 1, "White",
ethnicity == 2, "Black or African American",
ethnicity %in% c(4, 5, 6, 7, 8, 9, 10), "Asian",
default = "Other"),
region = fcase(
region == 1, "Northeast",
region == 2, "Midwest",
region == 3, "South",
region == 4, "West",
default = "idk"),
education = fcase(
education == 1, "Some high school or less",
education == 2, "High school graduate",
education == 3, "Other post high school vocational training",
education == 4, "Completed some college, but no degree",
education == 5, "Associate's degree",
education == 6, "Bachelor's degree",
education == 7, "Master's or professional degree",
education == 8, "Doctorate degree",
default = "idk"),
gender = ifelse(gender == 1, "Male", "Female")
)]
# Create this variable just to compare with the other variable `how_old_are_you` and filter out discrepancies
d[, how_old_are_you2 := fcase(
age >= 18 & age <= 24, "18-24 years old",
age >= 25 & age <= 34, "25-34 years old",
age >= 35 & age <= 44, "35-44 years old",
age >= 45 & age <= 54, "45-54 years old",
age >= 55 & age <= 64, "55-64 years old",
age >= 65, "65+ years old",
default = "idk"
)]
# consider cleaning hhi (household income) and political party
# more data cleaning
filtered_d <- d %>%
# filter out bad data. Can decide later what isn't necessary to filter out.
# This shrinks the data size from 504 to 448
filter(
#complier == TRUE,  # 39 non-compliers
duration_in_seconds <= 1000,  # 23 ppl took more than 1000 seconds and are outliers
!(taken_test_before == 'Yes' & familiar_with_test == 'No'),  # 6 ppl not answering questions correctly
(what_is_your_gender == gender), # 9 ppl answered their gender incorrectly
how_old_are_you == how_old_are_you2,  # 22 ppl answered their age incorrectly
response_id != bad_ids,  # 17 people answered 45/50 of the question with the same answer. (3 of which are non-compliers)
) %>%
# drop unnecessary vars
# we didn't get recipient name info, everyone finished, and other vars are unnecessary
select(-how_old_are_you2, -recipient_last_name:-external_data_reference,
-response_type, -progress, -finished, -distribution_channel, -user_language, -rid)
# separately make dataset of compliers only
filtered_compliers <- filtered_d %>% filter(complier)
# function to run one power test
# i run a regression on each factor individually
# recommended to set the alpha to .05/5 for bonferonni adjustment
power_analysis_one_test <- function(samp_size = 50, treatment_split = .5,
force_even_split = T, tau = -5, factor_mean = 50,
factor_sd = 10, alpha = .01){
# sample ppl and put them into treatment or control. Depends on if we want even splits or not
if (force_even_split){
df <- data.table(condition = c(rep("treatment", round(samp_size/2,0)), rep("control", round(samp_size/2,0))))
}else{
df <- data.table(condition = sample(c("treatment", "control"), size = samp_size, replace = T))
}
# now sample from the normal distribution to assign the treatment effect.
# if they are in treatment, they get the added "tau" effect.
# control just gets rnorm()
for (i in 1:5){
df[, paste0("factor", i) := ifelse(condition == "treatment",
rnorm(nrow(df[condition == "treatment",]), factor_mean + tau, factor_sd),
rnorm(nrow(df[condition == "control",]), factor_mean, factor_sd)
)]
}
# finally, calculate p-value for every personality factor
pvals <- c()
for (i in 1:5){
fit <- summary(lm(as.formula(paste0("factor", i, "~ condition")), data = df))
pval <- fit$coefficients[2,4]
pvals <- c(pvals, pval)
}
# are any of them significant?
sig <- sum(pvals < alpha) > 0
# return boolean for if it's significant or not
return(sig)
}
# Changing the sample size and running the experiment 1,000 times at various sample sizes and calculating the power.
adjust_sample_size <- function(samp_sizes, iter=1000, verbose=F){
output_samp_size <- c()
for (i in samp_sizes){
output_samp_size <- c(output_samp_size,
mean(sapply(1:iter, function(x) power_analysis_one_test(
samp_size = i, treatment_split = .5, force_even_split = T,
tau = 3, factor_mean = 50, factor_sd = 15))))
if(verbose){
print(paste0("Sample size ", i, " done."))
}
}
df_out <- data.table(
sample_size = samp_sizes,
power = output_samp_size
)
return(df_out)
}
set.seed(1)
df1 <- adjust_sample_size(seq(50, 500, 50), iter=300)
df1
print(df1)
filtered_d
filtered_compliers %>% dim
filtered_d %>% dim
504 - 448
448 - 416
d %>% glimpse
glimpse(df)
d[,.N, by = region]
d[.N, by = how_old_are_you]
d[,.N, by = how_old_are_you]
d[,.N, by = education_highest]
df %>% glimpse
d[,.N, by = ethnicity]
library(data.table)
library(tidyverse)
library(janitor)
library(ggplot2)
library(dplyr)
library(patchwork)
library(tidyverse)
library(lmtest)
library(stargazer)
library(sandwich)
library(knitr)
d <- fread('../data/W241_Survey_Results_Clean.csv')
full_data <- fread('../data/full_data.csv')
# checking out fishy responses from the full dataset
q_cols <- full_data %>% select(i_am_the_life_of_the_party:i_am_full_of_ideas) %>% names()
df_long <- melt.data.table(full_data, measure.vars = q_cols, variable.name = "question", value.name = "answer")
# 10 people just put the same thing every time
# df_long[,.N, by = c("response_id", "answer")][N == 50]
# 17 people basically put the same answer all the way down, with only slight variations
# df_long[,.N, by = c("response_id", "answer")][N >= 45]
# save the IDs of these 17 people to filter out later
bad_ids <- df_long[,.N, by = c("response_id", "answer")][N >= 45]$response_id
# define complier and treatment variables
d[, ":=" (
complier = ifelse(((d[, dob_day] %% 2 == 1) & (d[, compliance_q_glass] == 'Confetti (colored)')) |
((d[, dob_day] %% 2 == 0) & (d[, compliance_q_mclaughlin] == 'Fish')), TRUE, FALSE),
treatment = ifelse(d[, dob_day] %% 2 == 0, 1, 0)
)]
# Binarize hispanic variable
d[, hispanic := ifelse(hispanic %in% c(1, 15), 0, 1)]
# make some vars more descriptive
d[, ':=' (
# Simplify ethnicity breakdowns
ethnicity = fcase(
ethnicity == 1, "White",
ethnicity == 2, "Black or African American",
ethnicity %in% c(4, 5, 6, 7, 8, 9, 10), "Asian",
default = "Other"),
region = fcase(
region == 1, "Northeast",
region == 2, "Midwest",
region == 3, "South",
region == 4, "West",
default = "idk"),
education = fcase(
education == 1, "Some high school or less",
education == 2, "High school graduate",
education == 3, "Other post high school vocational training",
education == 4, "Completed some college, but no degree",
education == 5, "Associate's degree",
education == 6, "Bachelor's degree",
education == 7, "Master's or professional degree",
education == 8, "Doctorate degree",
default = "idk"),
gender = ifelse(gender == 1, "Male", "Female")
)]
# Create this variable just to compare with the other variable `how_old_are_you` and filter out discrepancies
d[, how_old_are_you2 := fcase(
age >= 18 & age <= 24, "18-24 years old",
age >= 25 & age <= 34, "25-34 years old",
age >= 35 & age <= 44, "35-44 years old",
age >= 45 & age <= 54, "45-54 years old",
age >= 55 & age <= 64, "55-64 years old",
age >= 65, "65+ years old",
default = "idk"
)]
# consider cleaning hhi (household income) and political party
# more data cleaning
filtered_d <- d %>%
# filter out bad data. Can decide later what isn't necessary to filter out.
# This shrinks the data size from 504 to 448
filter(
#complier == TRUE,  # 39 non-compliers
duration_in_seconds <= 1000,  # 23 ppl took more than 1000 seconds and are outliers
!(taken_test_before == 'Yes' & familiar_with_test == 'No'),  # 6 ppl not answering questions correctly
(what_is_your_gender == gender), # 9 ppl answered their gender incorrectly
how_old_are_you == how_old_are_you2,  # 22 ppl answered their age incorrectly
response_id != bad_ids,  # 17 people answered 45/50 of the question with the same answer. (3 of which are non-compliers)
) %>%
# drop unnecessary vars
# we didn't get recipient name info, everyone finished, and other vars are unnecessary
select(-how_old_are_you2, -recipient_last_name:-external_data_reference,
-response_type, -progress, -finished, -distribution_channel, -user_language, -rid)
# separately make dataset of compliers only
filtered_compliers <- filtered_d %>% filter(complier)
# function to run one power test
# i run a regression on each factor individually
# recommended to set the alpha to .05/5 for bonferonni adjustment
power_analysis_one_test <- function(samp_size = 50, treatment_split = .5,
force_even_split = T, tau = -5, factor_mean = 50,
factor_sd = 10, alpha = .01){
# sample ppl and put them into treatment or control. Depends on if we want even splits or not
if (force_even_split){
df <- data.table(condition = c(rep("treatment", round(samp_size/2,0)), rep("control", round(samp_size/2,0))))
}else{
df <- data.table(condition = sample(c("treatment", "control"), size = samp_size, replace = T))
}
# now sample from the normal distribution to assign the treatment effect.
# if they are in treatment, they get the added "tau" effect.
# control just gets rnorm()
for (i in 1:5){
df[, paste0("factor", i) := ifelse(condition == "treatment",
rnorm(nrow(df[condition == "treatment",]), factor_mean + tau, factor_sd),
rnorm(nrow(df[condition == "control",]), factor_mean, factor_sd)
)]
}
# finally, calculate p-value for every personality factor
pvals <- c()
for (i in 1:5){
fit <- summary(lm(as.formula(paste0("factor", i, "~ condition")), data = df))
pval <- fit$coefficients[2,4]
pvals <- c(pvals, pval)
}
# are any of them significant?
sig <- sum(pvals < alpha) > 0
# return boolean for if it's significant or not
return(sig)
}
# Changing the sample size and running the experiment 1,000 times at various sample sizes and calculating the power.
adjust_sample_size <- function(samp_sizes, iter=1000, verbose=F){
output_samp_size <- c()
for (i in samp_sizes){
output_samp_size <- c(output_samp_size,
mean(sapply(1:iter, function(x) power_analysis_one_test(
samp_size = i, treatment_split = .5, force_even_split = T,
tau = 3, factor_mean = 50, factor_sd = 15))))
if(verbose){
print(paste0("Sample size ", i, " done."))
}
}
df_out <- data.table(
sample_size = samp_sizes,
power = output_samp_size
)
return(df_out)
}
set.seed(1)
df1 <- adjust_sample_size(seq(50, 500, 50), iter=300)
df1
# plot
df1 %>%
ggplot(aes(x = sample_size, y = power)) +
geom_line() +
labs(title = "Power as Sample Size Increases",
subtitle = "Assumes test scores have a standard deviation of 15, with a treatment effect of 3",
y = "Power", x = "Sample Size") +
theme_minimal()
df1
read_lines(
"50 0.1266667
100 0.2300000
150 0.3266667
200 0.4600000
250 0.5500000
300 0.6733333
350 0.7400000
400 0.8333333
450 0.8700000
500 0.8933333")
read_csv(
"50,0.1266667
100,0.2300000")
temp = read_csv(
"50,0.1266667
100,0.2300000")
temp
df1
temp = read_csv(
"sample_size,power
50,0.1266667
100,0.2300000
150,0.3266667
200,0.4600000
250,0.5500000
300,0.6733333
350,0.7400000
400,0.8333333
450,0.8700000
500,0.8933333")
temp
full_data %>% dim
#d <- fread("../W241_Survey_Results_Clean.csv")
d <- fread("~/Desktop/W241_Survey_Results_Clean.csv")
dim(d)
glimpse(d)
# Original data file isn't saved to github, only google drive.
# Download the survey data and the questions_scores.csv file.
# Then specify the path where you saved the files
# After that, everything else below should work
path <- "~/Desktop/data"
df <- "W241_Survey_Results.csv" %>% file.path(path, .) %>% fread
q_scores <- "question_scores.csv" %>% file.path(path, .) %>% fread
dim(df)
glimpse(df)
